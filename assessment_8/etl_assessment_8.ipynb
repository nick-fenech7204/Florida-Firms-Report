{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL Report: \n",
    "## Firm Charaterstics Among the Three Largest Municipalities in Florida"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We asked ourselves how do the three largest municipalities (Orlando, Miami, Tampa) in Florida compare in terms of firm charaterstics such as employee/firm amounts, diversity, and other KPI's on the region's economy.\n",
    "\n",
    "\n",
    "This ETL report will go over the process of extracting, transforming, and loading data from two different data sources.\n",
    "* The United States Census Bureau \n",
    "* Federal Reserve Bank of St. Louis \n",
    "\n",
    "All steps will be outlined below for the ETL process using Python and the Pandas library."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction: Part 1 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first steps first extracting this data were obtaining the proper API keys to access the sets. \n",
    "*(Please note, if you do not plan on querying more 500 times a day, you can skip obtaining the key)\n",
    "However, to obtain an API key for the Census Bureau, please click on the following [link](https://www.census.gov/data/developers/guidance/api-user-guide.Help_&_Contact_Us.html\n",
    ")\n",
    "\n",
    "Once a key is obtained, you will need to query the columns and sets you are interested in, see below for the code used to query the needed data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the Pandas Library as pd to work with dataframes and the requests Library to perform the API call\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then\n",
    "* We use the variable endpoint to define the query\n",
    "* Then use a GET request to obtain the and store the API\n",
    "* In the variable df, we covert the response from JSON to a Pandas dataframe\n",
    "* And finally, to a CSV file to be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = 'https://api.census.gov/data/2019/abscs?get=NAME,GEO_ID,RCPSZFI,NAICS2017_LABEL,ETH_GROUP,SEX,EMPSZFI,EMP,FIRMPDEMP&for=metropolitan%20statistical%20area/micropolitan%20statistical%20area:33100&NAICS2017=00'\n",
    "response = requests.get(endpoint)\n",
    "df = pd.DataFrame.from_records(response.json()[1:], columns=response.json()[0])\n",
    "df.to_csv('../assessment_8/data/census_data_miami.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = 'https://api.census.gov/data/2019/abscs?get=NAME,GEO_ID,RCPSZFI,NAICS2017_LABEL,ETH_GROUP,SEX,EMPSZFI,EMP,FIRMPDEMP&for=metropolitan%20statistical%20area/micropolitan%20statistical%20area:36740&NAICS2017=00'\n",
    "response = requests.get(endpoint)\n",
    "df = pd.DataFrame.from_records(response.json()[1:], columns=response.json()[0])\n",
    "df.to_csv('../assessment_8/data/census_data_orlando.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = 'https://api.census.gov/data/2019/abscs?get=NAME,GEO_ID,RCPSZFI,NAICS2017_LABEL,ETH_GROUP,SEX,EMPSZFI,EMP,FIRMPDEMP&for=metropolitan%20statistical%20area/micropolitan%20statistical%20area:33100&NAICS2017=00'\n",
    "response = requests.get(endpoint)\n",
    "df = pd.DataFrame.from_records(response.json()[1:], columns=response.json()[0])\n",
    "df.to_csv('../assessment_8/data/census_data_tampa.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Please be aware, when querying from this spefic API, it will help to use the documentation provided to determine which columns one would like to query, feel free to view them [here](https://www.census.gov/programs-surveys/abs/technical-documentation/api.2019.html#list-tab-702748516). Also, the CSV path may be different depending on your machine, please adjust accordingly."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction: Part 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the above was for accessing the data from The United States Census Bureau, below are the steps for extracting the Federal Reserve Bank of St. Louis data sets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please access the revelent data from these three links:\n",
    "* [Miami](https://fred.stlouisfed.org/series/RGMP33100)\n",
    "* [Orlando](https://fred.stlouisfed.org/series/NGMP36740)\n",
    "* [Tampa](https://fred.stlouisfed.org/series/NGMP45300)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On each link, you will see a dashboard visual for the municipalities, to the right will be a blue download button, please click on it and choose to download as a CSV.\n",
    "\n",
    "Once all threes CSV files are downloaded, be sure to rename them to the relevant city, and place them within the same working folder as you have the rest of your data and Juypter Noteboook."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation : Part 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the uncleaned data in its raw form from the API, we can transform it to only contain data relevant to our question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create a new varaible to read in the raw CSV data for each municipality, this will allow us to manipulate the data frames as needed\n",
    "\n",
    "See below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_miami = pd.read_csv('../assessment_8/data/census_data_miami.csv')\n",
    "census_tampa = pd.read_csv('../assessment_8/data/census_data_tampa.csv')\n",
    "census_orlando = pd.read_csv('../assessment_8/data/census_data_orlando.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we will need to complete the cleaning steps for each data set, the relvant code is posted below to change columns, values types, and remove any information that is not needed\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Change current column names to more readable names, as well as drop columns outside your needs(complete for each dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_rename_columns = census_miami.rename(columns={\n",
    "'NAME':'Municipality', 'RCPSZFI': 'Firm_Sale_Amount', 'ETH_GROUP' : 'Ethnicity', 'SEX': 'Gender',\n",
    "'EMPSZFI': 'Firm_Employee_Size', 'EMP': 'Employee_Amount', 'FIRMPDEMP': 'Amount_of_Firms'})\n",
    "\n",
    "check_columns = drop_rename_columns.drop(['NAICS2017_LABEL', 'NAICS2017', 'metropolitan statistical area/micropolitan statistical area', 'Firm_Employee_Size'], axis=1)\n",
    "check_columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will replace values, due to the way the data is preseneted, you will need to reference the documentation for value codes depending on the columns. Values codes can be found using this [link](https://www.census.gov/programs-surveys/abs/technical-documentation/api.2019.html#list-tab-702748516) (same as mentioned earlier)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Replace value codes with the relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_columns.loc[:,'Firm_Sale_Amount'] = check_columns['Firm_Sale_Amount'].astype(str).replace({\n",
    "'511': 'Less than $5,000', '518': '$5,000,$9,000', '531': '$500,000-$999,999', '519' : ' $10,000-$24,999', \n",
    "'521': '$25,000-$49,999', '522' : '$50,000-$99,999', '523': '$100,000-$249,999',\n",
    "'525': '$250,000 to $499,999', '532': ' $1,000,000 or more' })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Be sure to keep track of you value types, replacing the incorrect value type will result in an error, reference your dataframe using \n",
    "```python\n",
    "your_data_frame.info()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_values = (check_columns\n",
    "    .replace({'Gender':{1: 'Total'}})\n",
    "    .replace({'Gender':{2: 'Female'}})\n",
    "    .replace({'Gender':{3: 'Male'}})\n",
    "    .replace({'Gender':{4: 'Equally male/female'}})\n",
    "    .replace({'Gender':{96: 'Classified'}})\n",
    "    .replace({'Gender':{98: 'Unclassificable'}})\n",
    "    .replace({'Ethnicity':{ 1 : 'Total'}})\n",
    "    .replace({'Ethnicity':{20: 'Hispanic'}})\n",
    "    .replace({'Ethnicity':{28: 'Equally Hispanic/non-Hispanic'}})\n",
    "    .replace({'Ethnicity':{29: 'Non-Hispanic'}})\n",
    "    .replace({'Ethnicity':{96: 'Classifiable'}})\n",
    "    .replace({'Ethnicity':{98: 'Unclassifiable'}})\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will also need to remove rows that do not contain any data, this set uses 'Total' or numeric objects to represent null values\n",
    "<!-- ![image info](./transform_table.png) -->\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please see below the code needed to replace numeric objects:\n",
    "\n",
    "- To remove numeric objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_miami = replaced_values.drop(replaced_values[replaced_values['Firm_Sale_Amount'] == '1'].index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will add a state column to for reference, as well as replace total with null values, see the code below:\n",
    "\n",
    "* Adding state of Florida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_miami['State'] = pd.Series(['Florida']*139)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, your dataframe should look similar to this snippet below:\n",
    "\n",
    "\n",
    "![image info](../assessment_8/Images/Screenshot%20(79).png)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can conduct the final step of concatination of all tables, as well as taking care of null values\n",
    "\n",
    "* Here, we can replace 'Total' with null values\n",
    "\n",
    "* *remember, there are three seperate data frames that will need all the above code applied to each one, in this final step we are appending all the dataframes into one large dataframe \n",
    "\n",
    "\n",
    "The code below is an exception that can be applied to all three dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "municipality_dataframe = pd.concat([census_miami, census_orlando, census_tampa])\n",
    "municipality_df = municipality_dataframe.replace({'Total': 'null'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your Final table should resemble the one below:\n",
    "\n",
    "![image info](../assessment_8/Images/Screenshot%20(80).png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, save the dataframe as a CSV to your data folder, see code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "municipality_df.to_csv('../assessment_8/data/municipality_df.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation: Part 2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for the FRED economic data sets, there are a couple transformation steps to get the table to normal form\n",
    "\n",
    "* Read in files\n",
    "* Merge tables\n",
    "* rename columns\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please see the code below to read in the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orlando_gdp = pd.read_csv('../assessment_8/data/orlando_gpd.csv')\n",
    "miami_gdp = pd.read_csv('../assessment_8/data/miami_gdp.csv')\n",
    "tampa_gpd = pd.read_csv('../assessment_8/data/tampa_gdp.csv')\n",
    "miami_gdp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Merge all three sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(orlando_gdp,miami_gdp, on='DATE', how='left')\n",
    "df = pd.merge(merged,tampa_gpd, on= 'DATE', how='left')\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Rename the columns for easier readability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_final= df.rename(columns={'NGMP36740': 'Tampa_GDP', 'RGMP33100': 'Miami_GDP', 'NGMP45300': 'Orlando_GDP'})\n",
    "gdp_final"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your final dataframe should look like this:\n",
    "\n",
    "\n",
    "\n",
    "![image info](../assessment_8/Images/Screenshot%20(81).png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, save the final GDP dataframe to your data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_final.to_csv('../assessment_8/data/gdp_df.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all steps are completed, you should be left with two data frames, one from our Census API that has Orlando, Miami, and Tampa municipality business characteristics as well as the GDP over the last decades for each of the municipalities\n",
    "\n",
    "These data frames will be helpful in creating visuals to compare KPI's from the cities, thus allowing us to answer how well one is doing to the other, and allow us to draw conclusions on why one would be performing better than the other"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the process to load is fairly simple since all ETL steps are completed within Python, please see below:\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Make sure to load the libraries needed for your visualizations, please see the ones used in our process below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*If you do not have any of these libraries installed, please see this [documentation](https://dylancastillo.co/how-to-plot-with-python-popular-graphs-using-pandas-matplotlib-seaborn-and-plotly-express/#start-jupyter-notebook-and-import-libraries) for assistance\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Read the CSV files of the two dataframes into your Juypter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "municipality_df = pd.read_csv('../assessment_8/data/municipality_df.csv')\n",
    "gdp_df = pd.read_csv('../assessment_8/data/gdp_df.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes the ETL process for our data sets, there are many steps involved getting the data normalized to the point of use, however, we feel this ETL Report can be very helpful for obtaining not only the prefered data for our process, but can be a great reference for any data request whether from an API or file. \n",
    "\n",
    "\n",
    "If there are additonal questions, feel free to explore the documentation below to assist\n",
    "\n",
    "* [API_Calling](https://www.nylas.com/blog/use-python-requests-module-rest-apis/)\n",
    "\n",
    "* [ETL_Process](https://www.nylas.com/blog/use-python-requests-module-rest-apis/)\n",
    "\n",
    "* [Pandas_CheatSheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenviorment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
